---
title: "Session 3: tidyverse and publication-ready figures"
author: "Nils"
date: "`r Sys.Date()`"
output: html_notebook
---

In this session, I will go through the concept of tidy data in R. 
Tidy data is broadly defined as having individual samples in the rows of a data matrix while the columns define variables (or features) describing the samples [https://en.wikipedia.org/wiki/Tidy_data](https://en.wikipedia.org/wiki/Tidy_data).
This is the standard format for any sort of statistical analysis.

We will also discuss the `long` and `wide` data format.

**Disclaimer:** Tidyverse offers functionality, which is quite similar to base R's behaviour but with higher efficiency and less typing.
However, for beginners it can get confusing to mix both ways of programming.

The `tidyverse` library offers a set of libraries that handle tidy data in R:

```{r load-libraries}
library(tidyverse)
```

From the full set of tools, I will be talking about the `tibble`, `readr`, `tidyr`, `dplyr`, `magrittr` and `ggplot2` package in more detail.
This tutorial will closely follow examples provided in the [R for data science book](https://r4ds.had.co.nz/index.html).

The general workflow for data analysis in R is:

1. Reading in your data
2. Tidying your data
3. Transforming your data
4. Visualizing your data
5. Modelling your data

In the last session, we have talked about different ways of reading in the data.

## Introduction

To understand the following session, I will need to introduce a new data type: tibble

### Tibbles

Tibbles are an enhanced version of the base R `data.frame` but with similar functionality.

```{r create-tibble}
data(iris)
iris
as_tibble(iris)
```

Only the first 10 entries are shown.

Tibbles can be created using the `tibble` function:

```{r create-tibble-2}
tb <- tibble(x = 1:5, y = 1, z = x ^ 2 + y)
tb

df <- data.frame(x = 1:5, y = 1)
df$z <- df$x ^ 2 + df$y
df
```

Coercion into `data.frame` works via `as.data.frame`:

```{r coercion}
as.data.frame(tb)
```

Subsetting is enhanced for `tibble` compared to `data.frames` and `stringAsFactor` argument is ignored.

```{r subsetting}
df <- data.frame(abc = 1:3, xyz = c("a", "b", "c"))
df
df$x
df$xyz
df["x"]
df["xyz"]
df[["xyz"]]
df[,"xyz"]
df[,c("abc", "xyz")]

tb <- tibble(abc = 1:3, xyz = c("a", "b", "c"))
tb$x
tb$xyz
tb["x"]
tb["xyz"]
tb[["xyz"]]
tb[,"xyz"]
tb[,c("abc", "xyz")]
```

## Reading in data

We have discussed the base R `read.table` and `read.csv` function in the last session.
Now we will work with the `readr` package to read data into tibbles with a few enhancements:

```{r read_csv}
cur_file <- readr::read_csv("~/Github/IntroDataAnalysis/Data/iris.csv")
cur_file 

cur_file <- readr::read_csv("~/Github/IntroDataAnalysis/Data/iris.csv", col_names = FALSE)
cur_file 

cur_file <- readr::read_csv("~/Github/IntroDataAnalysis/Data/iris.csv", na = "setosa")
cur_file 
```

The `read_csv` and other functions of the `readr` package are faster, generate tibbles, use rownames and ignore `stringAsFactor`.

By default, `readr` reads in the first 1000 lines of the file and for each column guesses the data type.
This behaviour can be overwritten:

```{r read_csv-2}
cur_file <- readr::read_csv("~/Github/IntroDataAnalysis/Data/iris.csv", 
                            col_types = cols(
                                Sepal.Length = col_character(),
                                Sepal.Width = col_character(),
                                Petal.Length = col_character(),
                                Petal.Width = col_character(),
                                Species = col_character()
                                ))
cur_file 
```

Extension to previous session:

At this point it is also usefult to mention the `saveRDS` and `readRDS` function.
They save individual R objects "as is" on disc:

```{r saveRDS}
cur_file <- readr::read_csv("~/Github/IntroDataAnalysis/Data/iris.csv")
saveRDS(cur_file, "~/Github/IntroDataAnalysis/Data/iris.rds")
cur_file_2 <- readRDS("~/Github/IntroDataAnalysis/Data/iris.rds")
cur_file_2
```

## Tidying up your data

This section will introduce the `tidyr` package.
A tidy dataset is defined as:

1. Each variable must have its own column.
2. Each observation must have its own row.
3. Each value must have its own cell.

An example is given by the follwing dataset:

```{r tidy_data-example}
table1
```

However, datasets often come in all types of forms that do not follow these rules (messy data).
The `tidyr` package provides the `pivot_longer` and `pivot_wider` function to handle the ransformation from messy to tidy data.
Similar functions are exported from the `reshape2` and `data.table` package (`melt`, `acast`, `dcast`).

Here is an example:

```{r messy_data-example}
table4a
```

The `pivot_longer` function provides a long format tibble storing individual observations in rows and variables in columns.

```{r pivot_longer}
pivot_longer(table4a, cols = c("1999", "2000"), names_to = "year", values_to = "cases")
```

Another example is the following dataset:

```{r messy_data-example-2}
table2
```

To make the data wider, the `tidyr` package provides the `pivot_wider` function:

```{r pivot_wider}
pivot_wider(table2, names_from = "type", values_from = "count")
```

The `tidyr` package can also be used to split and merge columns.

As an example, we use this messy data:

```{r messy_example-3}
table3
```

The `rate` column can be split using the `separate` operation:

```{r splitting-merging}
separate(table3, col = "rate", into = c("cases", "populations"), sep = "/", convert = TRUE)
```

On the other hand, `tidyr` can also unite data:

```{r unite}
table5
unite(table5, col = "year", century, year, sep = "")
```

## The pipe operator

The `magrittr` package exports a set of operators taht facilitates the concatenations of operations in R.
At this point, I only want to mention the `%>%` forward pipe operator.

This allows us use functions in the following way:

```{r piping}
table5 %>% unite(col = "year", century, year, sep = "")
```

From now on, we will only use the pipe operator.

## Data transformation

Wrangling = tidying + transforming




## Visualize your data

